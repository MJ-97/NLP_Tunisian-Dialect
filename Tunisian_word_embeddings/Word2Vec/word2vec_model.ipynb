{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import gensim \n",
    "from gensim.models import Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 29: expected 1 fields, saw 2\\nSkipping line 259: expected 1 fields, saw 2\\nSkipping line 6339: expected 1 fields, saw 2\\nSkipping line 6341: expected 1 fields, saw 2\\nSkipping line 6342: expected 1 fields, saw 2\\nSkipping line 6636: expected 1 fields, saw 2\\nSkipping line 7431: expected 1 fields, saw 2\\nSkipping line 7536: expected 1 fields, saw 2\\nSkipping line 7537: expected 1 fields, saw 2\\nSkipping line 7687: expected 1 fields, saw 2\\nSkipping line 7917: expected 1 fields, saw 2\\nSkipping line 8387: expected 1 fields, saw 2\\nSkipping line 8972: expected 1 fields, saw 2\\nSkipping line 9963: expected 1 fields, saw 2\\nSkipping line 13698: expected 1 fields, saw 2\\nSkipping line 13703: expected 1 fields, saw 2\\nSkipping line 14709: expected 1 fields, saw 2\\nSkipping line 14812: expected 1 fields, saw 2\\nSkipping line 14847: expected 1 fields, saw 2\\nSkipping line 14879: expected 1 fields, saw 2\\nSkipping line 15018: expected 1 fields, saw 2\\nSkipping line 15036: expected 1 fields, saw 2\\nSkipping line 15037: expected 1 fields, saw 2\\nSkipping line 15038: expected 1 fields, saw 2\\nSkipping line 15039: expected 1 fields, saw 2\\nSkipping line 15040: expected 1 fields, saw 2\\nSkipping line 15041: expected 1 fields, saw 2\\nSkipping line 15141: expected 1 fields, saw 2\\nSkipping line 15281: expected 1 fields, saw 2\\nSkipping line 19700: expected 1 fields, saw 2\\nSkipping line 21762: expected 1 fields, saw 2\\nSkipping line 22671: expected 1 fields, saw 2\\nSkipping line 24584: expected 1 fields, saw 2\\nSkipping line 24811: expected 1 fields, saw 2\\nSkipping line 26345: expected 1 fields, saw 2\\nSkipping line 27988: expected 1 fields, saw 2\\nSkipping line 30031: expected 1 fields, saw 2\\nSkipping line 30039: expected 1 fields, saw 2\\nSkipping line 30122: expected 1 fields, saw 2\\nSkipping line 30322: expected 1 fields, saw 2\\nSkipping line 30392: expected 1 fields, saw 2\\nSkipping line 30713: expected 1 fields, saw 2\\nSkipping line 30823: expected 1 fields, saw 2\\nSkipping line 30858: expected 1 fields, saw 2\\nSkipping line 30907: expected 1 fields, saw 2\\nSkipping line 31029: expected 1 fields, saw 2\\nSkipping line 31421: expected 1 fields, saw 2\\nSkipping line 31471: expected 1 fields, saw 2\\nSkipping line 32051: expected 1 fields, saw 2\\nSkipping line 32064: expected 1 fields, saw 2\\nSkipping line 32446: expected 1 fields, saw 2\\nSkipping line 34600: expected 1 fields, saw 2\\nSkipping line 35075: expected 1 fields, saw 2\\nSkipping line 35158: expected 1 fields, saw 2\\nSkipping line 35225: expected 1 fields, saw 2\\nSkipping line 35340: expected 1 fields, saw 2\\nSkipping line 35479: expected 1 fields, saw 2\\nSkipping line 35542: expected 1 fields, saw 2\\nSkipping line 35596: expected 1 fields, saw 2\\nSkipping line 35621: expected 1 fields, saw 2\\nSkipping line 35678: expected 1 fields, saw 2\\nSkipping line 35884: expected 1 fields, saw 2\\nSkipping line 36060: expected 1 fields, saw 2\\nSkipping line 36065: expected 1 fields, saw 4\\nSkipping line 36083: expected 1 fields, saw 2\\nSkipping line 36174: expected 1 fields, saw 2\\nSkipping line 36353: expected 1 fields, saw 2\\nSkipping line 36354: expected 1 fields, saw 2\\nSkipping line 36362: expected 1 fields, saw 2\\nSkipping line 36365: expected 1 fields, saw 2\\nSkipping line 36461: expected 1 fields, saw 2\\nSkipping line 36539: expected 1 fields, saw 2\\nSkipping line 36815: expected 1 fields, saw 2\\nSkipping line 37095: expected 1 fields, saw 2\\nSkipping line 37267: expected 1 fields, saw 2\\nSkipping line 37273: expected 1 fields, saw 2\\nSkipping line 37341: expected 1 fields, saw 2\\nSkipping line 37415: expected 1 fields, saw 2\\nSkipping line 37481: expected 1 fields, saw 2\\nSkipping line 37603: expected 1 fields, saw 2\\nSkipping line 37709: expected 1 fields, saw 2\\nSkipping line 37906: expected 1 fields, saw 2\\nSkipping line 37976: expected 1 fields, saw 2\\nSkipping line 38259: expected 1 fields, saw 2\\nSkipping line 38305: expected 1 fields, saw 2\\nSkipping line 38744: expected 1 fields, saw 2\\nSkipping line 39619: expected 1 fields, saw 2\\nSkipping line 39620: expected 1 fields, saw 2\\nSkipping line 39779: expected 1 fields, saw 2\\nSkipping line 39896: expected 1 fields, saw 2\\nSkipping line 40272: expected 1 fields, saw 2\\nSkipping line 40376: expected 1 fields, saw 2\\nSkipping line 40449: expected 1 fields, saw 2\\nSkipping line 40513: expected 1 fields, saw 2\\nSkipping line 40637: expected 1 fields, saw 2\\nSkipping line 40757: expected 1 fields, saw 2\\nSkipping line 40810: expected 1 fields, saw 2\\nSkipping line 41157: expected 1 fields, saw 2\\nSkipping line 41220: expected 1 fields, saw 2\\nSkipping line 41475: expected 1 fields, saw 2\\nSkipping line 41899: expected 1 fields, saw 2\\nSkipping line 42134: expected 1 fields, saw 2\\nSkipping line 42464: expected 1 fields, saw 2\\nSkipping line 42545: expected 1 fields, saw 2\\nSkipping line 42978: expected 1 fields, saw 2\\nSkipping line 45645: expected 1 fields, saw 2\\nSkipping line 49046: expected 1 fields, saw 2\\nSkipping line 52096: expected 1 fields, saw 2\\nSkipping line 52639: expected 1 fields, saw 2\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>يا سيدي علي عيشوشه واله تمثل مليح وتمثيلها مقنع</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>امنه تصلح وزيره مراه عالاقل تعطي منظر باهي لتو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>حنان الشقراني احسن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بري روحي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>معلم يا لطفي</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0    يا سيدي علي عيشوشه واله تمثل مليح وتمثيلها مقنع\n",
       "1  امنه تصلح وزيره مراه عالاقل تعطي منظر باهي لتو...\n",
       "2                                 حنان الشقراني احسن\n",
       "3                                           بري روحي\n",
       "4                                       معلم يا لطفي"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data files downloaded from web\n",
    "data = pd.read_csv(\"/home/mahmoud/Desktop/Tunisian Dialect Language Model TDLM/corpus/corpus.txt\",\n",
    "                   header=None,sep='\\n',error_bad_lines=False)\n",
    "data.columns = [\"text\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(row):\n",
    "    return len(row.split())\n",
    "\n",
    "data[\"text\"]  = data[\"text\"].apply(str)\n",
    "data[\"text\"]  = data[\"text\"].apply(str.strip)\n",
    "\n",
    "data[\"Number_of_tokens\"]  = data[\"text\"].apply(count_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number_of_tokens</th>\n",
       "      <td>52603.0</td>\n",
       "      <td>6.61468</td>\n",
       "      <td>6.359828</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count     mean       std  min  25%  50%  75%    max\n",
       "Number_of_tokens  52603.0  6.61468  6.359828  1.0  3.0  5.0  8.0  261.0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52603, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Number_of_tokens</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>يا سيدي علي عيشوشه واله تمثل مليح وتمثيلها مقنع</td>\n",
       "      <td>9</td>\n",
       "      <td>[يا, سيدي, علي, عيشوشه, واله, تمثل, مليح, وتمث...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>امنه تصلح وزيره مراه عالاقل تعطي منظر باهي لتو...</td>\n",
       "      <td>14</td>\n",
       "      <td>[امنه, تصلح, وزيره, مراه, عالاقل, تعطي, منظر, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>حنان الشقراني احسن</td>\n",
       "      <td>3</td>\n",
       "      <td>[حنان, الشقراني, احسن]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بري روحي</td>\n",
       "      <td>2</td>\n",
       "      <td>[بري, روحي]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>معلم يا لطفي</td>\n",
       "      <td>3</td>\n",
       "      <td>[معلم, يا, لطفي]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Number_of_tokens  \\\n",
       "0    يا سيدي علي عيشوشه واله تمثل مليح وتمثيلها مقنع                 9   \n",
       "1  امنه تصلح وزيره مراه عالاقل تعطي منظر باهي لتو...                14   \n",
       "2                                 حنان الشقراني احسن                 3   \n",
       "3                                           بري روحي                 2   \n",
       "4                                       معلم يا لطفي                 3   \n",
       "\n",
       "                                               words  \n",
       "0  [يا, سيدي, علي, عيشوشه, واله, تمثل, مليح, وتمث...  \n",
       "1  [امنه, تصلح, وزيره, مراه, عالاقل, تعطي, منظر, ...  \n",
       "2                             [حنان, الشقراني, احسن]  \n",
       "3                                        [بري, روحي]  \n",
       "4                                   [معلم, يا, لطفي]  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    return str(x).split()\n",
    "\n",
    "\n",
    "data[\"words\"] = data[\"text\"].apply(tokenize)\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_letters_only(text):  \n",
    "    text = re.sub(\"à\",\"a\",text)\n",
    "    text = re.sub(\"é\",\"e\",text)\n",
    "    text = re.sub(\"è\",\"e\",text)\n",
    "    text = re.sub(\"ù\",\"u\",text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "data[\"text\"] = data[\"text\"].apply(keep_letters_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          يا سيدي علي عيشوشه واله تمثل مليح وتمثيلها مقنع\n",
       "1        امنه تصلح وزيره مراه عالاقل تعطي منظر باهي لتو...\n",
       "2                                       حنان الشقراني احسن\n",
       "3                                                 بري روحي\n",
       "4                                             معلم يا لطفي\n",
       "                               ...                        \n",
       "52598             wa7dek ya m3alem ena n7eb 8neyetek elkol\n",
       "52599    bravo enchalah lbe9in yamlo kifo 5ater tonis t...\n",
       "52600    yasir ta3jebni nhebha bercha fanana wa3liha le...\n",
       "52601                yser mjodra w moch 5arej 3liha idawer\n",
       "52602                                          wahdek olfa\n",
       "Name: text, Length: 52603, dtype: object"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "def to_corpus(row):\n",
    "    corpus.append(row.split())\n",
    "    return row\n",
    "\n",
    "data[\"text\"].apply(to_corpus)\n",
    "#corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    " \"size\":emb_dim, \n",
    "  \"alpha\":0.05, \n",
    "    \"window\":5, \n",
    "    \"min_count\":4,\n",
    "    \"workers\":8, \n",
    "    \"min_alpha\":0.0001, \n",
    "    \"sg\":1, \n",
    "    \"hs\":1, \n",
    "    \"negative\":0,\n",
    "    \"cbow_mean\":0,\n",
    "    \"iter\":15\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2v_model = Word2Vec(corpus,min_count=5 ,size=emb_dim ,window=5, alpha=0.01)\n",
    "w2v_model = Word2Vec(corpus,**settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.56 mins\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t = time()\n",
    "\n",
    "w2v_model.train(corpus, total_examples=w2v_model.corpus_count, epochs=50, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11426, 100)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.save_word2vec_format(\"Word2Vec_\"+str(emb_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11426, 100)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_matrix = w2v_model.wv.vectors\n",
    "w_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sotha', 0.5025343894958496),\n",
       " ('ma7leha', 0.49881526827812195),\n",
       " ('w', 0.49469253420829773),\n",
       " ('ama', 0.48090028762817383),\n",
       " ('tmathel', 0.4762348234653473),\n",
       " ('zeda', 0.46412956714630127),\n",
       " ('yeser', 0.4574049711227417),\n",
       " ('lawa7', 0.4555981457233429),\n",
       " ('barcha', 0.4549383521080017),\n",
       " ('ta7fona', 0.4530925750732422)]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(w2v_model.wv.index2entity)\n",
    "meta_data = w2v_model.wv.index2entity\n",
    "\n",
    "#w2v_model.wv.index2entity[0]\n",
    "type(w2v_model.wv.index2word)\n",
    "#w2v_model.wv.word_vec\n",
    "\n",
    "#w2v_model.wv[w2v_model.wv.index2entity[0]]\n",
    "\n",
    "#w_matrix[1000] == w2v_model.wv[w2v_model.wv.index2entity[1000]]\n",
    "\n",
    "w2v_model.wv.most_similar(positive=[\"tofla\"])\n",
    "\n",
    "#w2v_model[\"rajel\"] - w2v_model[\"mra\"] - w2v_model[\"rjel\"] + w2v_model[\"tofla\"]\n",
    "\n",
    "#w2v_model[\"khayeb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "wv_from_text = KeyedVectors.load_word2vec_format(datapath('/home/mahmoud/Desktop/Tunisian Dialect Language Model TDLM/Sentiment analysis/Word2Vec Embeddings/Word2Vec_100'), binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('كافون', 0.4329281151294708),\n",
       " ('محترمه', 0.430868923664093),\n",
       " ('مرا', 0.39773425459861755),\n",
       " ('يوفقها', 0.3764894902706146),\n",
       " ('لثقافه', 0.3656095862388611),\n",
       " ('الماضيه', 0.35368573665618896),\n",
       " ('انتي', 0.34869128465652466),\n",
       " ('سياسيه', 0.34168222546577454),\n",
       " ('النواب', 0.3416549861431122),\n",
       " ('يازعيم', 0.3369888663291931)]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_from_text.most_similar(positive=[\"امراه\",\"راجل\"],negative=[\"ولد\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('كافون', 0.4329281151294708),\n",
       " ('محترمه', 0.430868923664093),\n",
       " ('مرا', 0.39773425459861755),\n",
       " ('يوفقها', 0.3764894902706146),\n",
       " ('لثقافه', 0.3656095862388611),\n",
       " ('الماضيه', 0.35368573665618896),\n",
       " ('انتي', 0.34869128465652466),\n",
       " ('سياسيه', 0.34168222546577454),\n",
       " ('النواب', 0.3416549861431122),\n",
       " ('يازعيم', 0.3369888663291931)]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"امراه\",\"راجل\"],negative=[\"ولد\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38524628"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_from_text.similarity(\"معلم\",\"تحفون\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10449227"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_from_text.similarity(\"معلم\",\"خايب\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.061423913"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_from_text.similarity(\"كره\",\"ممثل\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = pd.read_csv(\"/home/mahmoud/Desktop/PFE_Tunisian_Dialect/data/test_labeled_processed.csv\")\n",
    "data.drop(axis=1,columns=[\"Unnamed: 0\",\"words\"],inplace=True)\n",
    "data[\"text\"] = data[\"text\"].apply(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data[\"text\"] = data[\"text\"].apply(remove_emojis)\n",
    "data[\"text\"] = data[\"text\"].apply(clean_text)\n",
    "data[\"text\"] = data[\"text\"].apply(remove_repeating_char)\n",
    "data[\"text\"] = data[\"text\"].apply(normalize_latin)\n",
    "data[\"text\"] = data[\"text\"].apply(normalize_arabic)\n",
    "data[\"text\"] = data[\"text\"].apply(keep_letters_only)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.to_csv(\"/home/mahmoud/Desktop/PFE_Tunisian_Dialect/data/test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "'/home/mahmoud/Desktop/Tunisian Dialect Language Model TDLM/Sentiment analysis/Word2Vec Embeddings/Word2Vec_100'\n",
    "w2v_path = '/home/mahmoud/Desktop/Tunisian Dialect Language Model TDLM/Sentiment analysis/Word2Vec Embeddings/Word2Vec_150'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load gensim word2vec\n",
    "#w2v_path = '/home/mahmoud/Desktop/Tunisian Dialect Language Model TDLM/Sentiment analysis/Word2Vec Embeddings/Word2Vec_100'\n",
    "w2v = KeyedVectors.load_word2vec_format(w2v_path)\n",
    "\n",
    "import io\n",
    "\n",
    "# Vector file, `\\t` seperated the vectors and `\\n` seperate the words\n",
    "\"\"\"\n",
    "0.1\\t0.2\\t0.5\\t0.9\n",
    "0.2\\t0.1\\t5.0\\t0.2\n",
    "0.4\\t0.1\\t7.0\\t0.8\n",
    "\"\"\"\n",
    "out_v = io.open('vecs_SG150.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "# Meta data file, `\\n` seperated word\n",
    "\"\"\"\n",
    "token1\n",
    "token2\n",
    "token3\n",
    "\"\"\"\n",
    "out_m = io.open('meta_SG150.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "# Write meta file and vector file\n",
    "for index in range(len(w2v.index2word)):\n",
    "    word = w2v.index2word[index]\n",
    "    vec = w2v.vectors[index]\n",
    "    out_m.write(word + \"\\n\")\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
