{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Tunisian sentiment analysis\n",
    "# The model is based on a pre-trained ELMo built on top of it linear layers for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MeG82Hx1d4sK"
   },
   "outputs": [],
   "source": [
    "#deal with tensors\n",
    "import torch   \n",
    "import sys\n",
    "#handling text data\n",
    "from torchtext import data    \n",
    "import pandas as pd\n",
    "from torchtext.vocab import Vectors\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FZAe7rNLd5Sh"
   },
   "outputs": [],
   "source": [
    "#Reproducing same results\n",
    "SEED = 2\n",
    "\n",
    "#Torch\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "#Cuda algorithms\n",
    "torch.backends.cudnn.deterministic = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlH1WxnCd9rc"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "bMnHDNaNmrUg",
    "outputId": "fc64aa2c-3036-4e54-ad7e-d08d438e9331"
   },
   "outputs": [],
   "source": [
    "train[\"text\"] = train[\"text\"].apply(str)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3_DeJSZf7ZW"
   },
   "outputs": [],
   "source": [
    "# corpus = list of tokenized sentences\n",
    "corpus = []\n",
    "def to_corpus(row):\n",
    "    new = str(row).split()\n",
    "    corpus.append(new)\n",
    "    return new\n",
    "\n",
    "train[\"samples\"] = train[\"text\"].apply(to_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lR6TdJvbUFHZ",
    "outputId": "2d9d265e-767b-4368-a715-b575cdd81404"
   },
   "outputs": [],
   "source": [
    "texts = \" \".join(train['text'].tolist())\n",
    "words = texts.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JbMJ60QGSKZ-",
    "outputId": "4c924569-a054-4010-db6d-708986e69d10"
   },
   "outputs": [],
   "source": [
    "dictionary = Counter(words)\n",
    "print(\"Size of Vocab\",len(dictionary))\n",
    "sorted_vocab = [\"<S>\",\"</S>\",\"<UNK>\"]\n",
    "sorted_vocab.extend([pair[0] for pair in dictionary.most_common()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "heU-1RHLacmw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1QLjG1csZbJW"
   },
   "outputs": [],
   "source": [
    "fp = open(\"train_vocab.txt\",\"w\")\n",
    "for i in sorted_vocab:\n",
    "  fp.write(i)\n",
    "  fp.write(\"\\n\")\n",
    "fp.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "ZzKxmD8s0SoM",
    "outputId": "8bdcfbbb-ea1e-4ac3-b248-49cd37a47116"
   },
   "outputs": [],
   "source": [
    "train_d = train.sample(frac=1).reset_index(drop=True)\n",
    "train_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d[\"count\"] = train_d[\"samples\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d = train_d[ train_d[\"count\"] <= 80 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d[\"count\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSjUMHo5TZwL"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \n",
    "    #define all the layers used in model\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, \n",
    "                 dropout,options_file,weight_file):\n",
    "        \n",
    "        #Constructor\n",
    "        super().__init__()          \n",
    "        \n",
    "        #Elmo Layers\n",
    "        self.elmo = Elmo(options_file, weight_file,1 ,requires_grad = True,dropout = dropout)            \n",
    "        \n",
    "        \n",
    "        #dense layer\n",
    "        self.linear = nn.Linear(embedding_dim,hidden_dim)\n",
    "        self.relu   = nn.ReLU()\n",
    "        \n",
    "        #dropout\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        #dense layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        #activation function\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, sentences):\n",
    "\n",
    "        #inputs for elmo of shape [batch size,time_steps,50]\n",
    "        embedded = self.elmo(sentences)\n",
    "        #print(len(embedded[\"elmo_representations\"]))\n",
    "\n",
    "        #retrieve the embeddings having shape [batch size, sent_len, emb dim]\n",
    "        embedded = embedded[\"elmo_representations\"][0]\n",
    "        embedded = embedded[:,0,:]\n",
    "        embedded = embedded.view(embedded.shape[0],embedded.shape[-1])\n",
    "        \n",
    "        dense_outputs = self.relu(self.linear(embedded))\n",
    "        \n",
    "        dense_outputs = self.dropout(dense_outputs)\n",
    "\n",
    "\n",
    "        #dense_outputs=self.fc(embedded)\n",
    "        dense_outputs=self.fc(dense_outputs)\n",
    "\n",
    "        #Final activation function\n",
    "        outputs=self.act(dense_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sWqFh0ErTb1U"
   },
   "outputs": [],
   "source": [
    "#No. of trianable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUgNhgtITuXs"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch import LongTensor\n",
    "\n",
    "#define metric\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "    \n",
    "    correct = (rounded_preds == y).float() \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DNwX2nLMTxqt"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "\n",
    "    \n",
    "    t0 = time()\n",
    "    print(\"\\ntraining process...:\")\n",
    "\n",
    "    #initialize every epoch \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    #set the model in training phase\n",
    "    model.train()  \n",
    "    iterator_length = len(iterator)\n",
    "    \n",
    "    for step, batch in enumerate(iterator):\n",
    "\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "          # Calculate elapsed time in minutes.\n",
    "          elapsed = format_time(time() - t0)\n",
    "          # Report progress.\n",
    "          print(' Batch {:>5,} of {:>5,}. Elapsed: {:}.'.format(step, len(iterator), elapsed)) \n",
    "         # [0]: input ids \n",
    "         # [1]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[1].to(device)\n",
    "\n",
    "        #resets the gradients after every batch\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        #convert to 1D tensor\n",
    "        predictions = model(b_input_ids).squeeze()\n",
    "        b_labels = b_labels.type_as(predictions)\n",
    "\n",
    "        #compute the loss\n",
    "        loss = criterion(predictions, b_labels)        \n",
    "        \n",
    "        #compute the binary accuracy\n",
    "        acc = binary_accuracy(predictions, b_labels)   \n",
    "        \n",
    "        #backpropage the loss and compute the gradients\n",
    "        loss.backward()       \n",
    "        \n",
    "        #update the weights\n",
    "        optimizer.step()      \n",
    "        \n",
    "        #loss and accuracy\n",
    "        epoch_loss += loss.item()  \n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    print(\"\\ntraining_epoch_loss: \",epoch_loss/iterator_length,\"\\ntraining_epoch_acc: \",epoch_acc/iterator_length)\n",
    "    \n",
    "        \n",
    "    return epoch_loss / iterator_length , epoch_acc / iterator_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ysyEIhujTymh"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    t0 = time()\n",
    "    print(\"\\nvalidation process...:\")\n",
    "    #initialize every epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    #deactivating dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    #deactivates autograd\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for step, batch in enumerate(iterator):\n",
    "\n",
    "            if step % 40 == 0 and not step == 0:\n",
    "               # Calculate elapsed time in minutes.\n",
    "               elapsed = format_time(time() - t0)\n",
    "               # Report progress.\n",
    "               print(' Batch {:>5,} of {:>5,}. Elapsed: {:}.'.format(step, len(iterator), elapsed)) \n",
    "            \n",
    "             # [0]: input ids \n",
    "             # [1]: labels\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_labels = batch[1].to(device)\n",
    "            \n",
    "            #convert to 1d tensor\n",
    "            predictions = model(b_input_ids).squeeze()\n",
    "            b_labels = b_labels.type_as(predictions) \n",
    "            \n",
    "            #compute loss and accuracy\n",
    "            loss = criterion(predictions, b_labels)\n",
    "            acc = binary_accuracy(predictions, b_labels)\n",
    "            \n",
    "            #keep track of loss and accuracy\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    print(\"\\nvalidation_epoch_loss: \",epoch_loss/len(iterator),\"\\nValidation_epoch_acc: \",epoch_acc/len(iterator))\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VmdqyRGNUFks"
   },
   "outputs": [],
   "source": [
    "def predict(model,iterator):\n",
    "    \n",
    "    model.eval()\n",
    "    preds = torch.FloatTensor().to(device)\n",
    "    labels = torch.FloatTensor().to(device)\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for step, batch in enumerate(iterator):            \n",
    "             # [0]: input ids \n",
    "             # [1]: labels\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_labels = batch[1].to(device)\n",
    "            \n",
    "            #convert to 1d tensor\n",
    "            predictions = model(b_input_ids).squeeze()\n",
    "            b_labels = b_labels.type_as(predictions) \n",
    "            \n",
    "            preds = torch.cat((preds,predictions))\n",
    "            labels = torch.cat((labels,b_labels))\n",
    "\n",
    "    return preds,labels\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uSjpHCHJnCoO"
   },
   "outputs": [],
   "source": [
    "sentences = train_d.samples.values.tolist()\n",
    "labels = train_d.label.values\n",
    "\n",
    "#sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(batch_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OK_Y30kdqSTW"
   },
   "outputs": [],
   "source": [
    "#input_ids of shape [len(batch), max sentence length, max word length]\n",
    "input_ids = batch_to_ids(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R9WO-OAgpzU_",
    "outputId": "80b55d8e-e9c6-422c-8f2a-f6b12f0a812b"
   },
   "outputs": [],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ruwQJvzjpqTV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=2020, test_size=0.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jMt_OZt_uOua",
    "outputId": "cb67c1b1-378c-4a0d-9af2-c24777db69b8"
   },
   "outputs": [],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "94A2H962jIRh",
    "outputId": "9694fad3-2489-4408-9c58-53ff296022bd"
   },
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGo6DgbTuxqR"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 128 \n",
    "\n",
    "\n",
    "#Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from shutil import copyfile\n",
    "if not os.path.exists(\"model\"):\n",
    "    os.makedirs(\"model\")\n",
    "\n",
    "copyfile(\"/home/mahmoud/Desktop/Tunisian Dialect Language Model TDLM/Sentiment analysis/ELMo/swb/vocab.txt\", \"model/vocab.txt\")\n",
    "\n",
    "copyfile(\"/home/mahmoud/Desktop/Tunisian Dialect Language Model TDLM/Sentiment analysis/ELMo/swb/checkpoint/options.json\", \"model/options.json\")\n",
    "\n",
    "copyfile(\"/home/mahmoud/Desktop/Tunisian Dialect Language Model TDLM/Sentiment analysis/ELMo/swb/swb_weights.hdf5\", \"model/swb_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#set n_characters to 262 in options.json\n",
    "a_file = open(\"model/options.json\", \"r\")\n",
    "\n",
    "json_object = json.load(a_file)\n",
    "\n",
    "a_file.close()\n",
    "#print(json_object)\n",
    "json_object[\"char_cnn\"][\"n_characters\"] = 262\n",
    "\n",
    "a_file = open(\"model/options.json\", \"w\")\n",
    "\n",
    "json.dump(json_object, a_file)\n",
    "\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pEGHXQ8SLynU"
   },
   "outputs": [],
   "source": [
    "vocab_file = \"train_vocab.txt\"\n",
    "\n",
    "#parameters of the model\n",
    "options_file = \"model/options.json\"\n",
    "weight_file = \"model/swb_weights.hdf5\"\n",
    "\n",
    "vocab_size = len(sorted_vocab)\n",
    "embedding_dim = 128    #Size of ELMO pretrained embeddings\n",
    "hidden_dim = 32\n",
    "output_dim = 1\n",
    "n_layers = 1 \n",
    "dropout = 0.5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "colab_type": "code",
    "id": "oUxQLeFz5Snt",
    "outputId": "ed4acd71-5615-4c1a-eb9b-e72f85277b3a"
   },
   "outputs": [],
   "source": [
    "model = Classifier(vocab_size,embedding_dim,hidden_dim,output_dim,dropout,\n",
    "              options_file,weight_file)\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "crtzI4gVv7u2",
    "outputId": "51a6ee5f-2c65-47fa-98f2-d142ee08e875"
   },
   "outputs": [],
   "source": [
    "print(\"model parameters:\\n\", count_parameters(model))\n",
    "N_trainable_params = count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWKVVHe5Wh7I"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from torch import optim\n",
    "#check whether cuda is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#push to cuda if available\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rv-0J-59wZts"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-7oezU2ydaD"
   },
   "outputs": [],
   "source": [
    "#import time\n",
    "import datetime\n",
    "def format_time(elapsed):\n",
    " '''\n",
    " Takes a time in seconds and returns a string hh:mm:ss\n",
    " '''\n",
    " # Round to the nearest second.\n",
    " elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    " # Format as hh:mm:ss\n",
    " return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MLTBSKjcyLcA",
    "outputId": "b2723884-c401-4a11-adac-237ce3bd8948"
   },
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "t1 = time()\n",
    "\n",
    "loss_values_eval = []\n",
    "acc_values_eval = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  train(model, train_dataloader, optimizer, criterion)\n",
    "  loss_eval,acc_eval = evaluate(model, validation_dataloader, criterion)\n",
    "  loss_values_eval.append(loss_eval)\n",
    "  acc_values_eval.append(acc_eval)\n",
    "\n",
    "\n",
    "elapsed = format_time(time()-t1)\n",
    "print(\"elapsed time: \",elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "f = pd.DataFrame(loss_values_eval)\n",
    "f.columns=['Loss']\n",
    "fig = px.line(f, x=f.index, y=f.Loss)\n",
    "fig.update_layout(title='Evaluation loss of the Model',xaxis_title='Epoch',yaxis_title='Loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jYs8QRzhLMlz"
   },
   "outputs": [],
   "source": [
    "f = pd.DataFrame(acc_values_eval)\n",
    "f.columns=['Accuracy']\n",
    "fig = px.line(f, x=f.index, y=f.Accuracy)\n",
    "fig.update_layout(title='Evaluation accuracy of the Model',xaxis_title='Epoch',yaxis_title='Accuracy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxAJ8fsBLMwf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "OZ_jETJtLNXj",
    "outputId": "31ef86c0-15bf-4668-b707-388d74d826d9"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test[\"text\"] = test[\"text\"].apply(str)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "IZW8a91bBp74",
    "outputId": "40bc0d31-d648-479e-a469-f8d759e5d09d"
   },
   "outputs": [],
   "source": [
    "def tokenize(row):\n",
    "  return row.split()\n",
    "\n",
    "test[\"samples\"] = test[\"text\"].apply(tokenize)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bhEvWQgIEuMB",
    "outputId": "a8e10985-c95e-42c5-bbbe-7a1a1bed9dad"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HhIMVUqSArJ1"
   },
   "outputs": [],
   "source": [
    "sentences = test.samples.values.tolist()\n",
    "labels = test.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xw8EGNtKAecb"
   },
   "outputs": [],
   "source": [
    "input_ids = batch_to_ids(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "CeDyc6OMCJNT",
    "outputId": "30133b29-57ad-459e-9d24-df6f78f5839d"
   },
   "outputs": [],
   "source": [
    "test_inputs = torch.tensor(input_ids)\n",
    "test_labels = torch.tensor(labels)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "test_data = TensorDataset(test_inputs, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDKjXqOtDhcc"
   },
   "outputs": [],
   "source": [
    "predictions, labels = predict(model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CWVf4A0HExB3",
    "outputId": "e69547e9-5eae-4bc9-b7c1-6b6ca8d95acd"
   },
   "outputs": [],
   "source": [
    "accuracy = float(binary_accuracy(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Elmo_Classifier.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
